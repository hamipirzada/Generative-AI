{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ea9bdf-a612-4674-96d4-dac14bc4866d",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "    Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in Natural Language Understanding(NLU) and Natural Language Processing(NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2843d620-fc51-4fc6-ad04-8768d4ac3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Problem\n",
    "# Comments on a product are positive review or negative review\n",
    "# Comments ---> eating, eat, eaten (Root word is eat) .,  [going, gone, goes] (root word is go)\n",
    "\n",
    "words = ['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'programs', 'history', 'finally', 'finalize']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871a5b3-facd-4fdf-b846-30a8b8ee943d",
   "metadata": {},
   "source": [
    "## Stemming Techniques: \n",
    "## 1. PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7aa856f-6bfd-4224-9ffd-aed5c2d98c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a22d3985-407d-44da-a195-726558070e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalize---->final\n"
     ]
    }
   ],
   "source": [
    "''The disadvantage of Stemming is that sometimes we may not get the correct word after performing\n",
    "stemming like in the below example, you can see how history got changed into histori'''\n",
    "\n",
    "stemming = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word+\"---->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eec09d21-f010-4503-94a6-23fce43694d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disadvantage\n",
    "\n",
    "stemming.stem(\"Congratulations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af315a-f6a1-4892-b416-c3efd1fd2f2b",
   "metadata": {},
   "source": [
    "## RegexpStemmer Class\n",
    "    NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer Algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Lets see with the help of some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13b472ee-230b-418b-8c40-50495551feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "regex_stemmer = RegexpStemmer('ing$|s$|e$|able$')\n",
    "regex_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6edd7d-7cf9-4ea0-880a-650e319b9f39",
   "metadata": {},
   "source": [
    "## Snowball Stemmer\n",
    "    The accuracy of this technique is better than PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a37a08a2-d52e-42a4-a9f1-fc979f644ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalize---->final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sball_stemmer = SnowballStemmer('english')\n",
    "for word in words:\n",
    "    print(word+'---->'+sball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c701ed82-91dd-4fa0-bd5e-50591a3aaab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between PorterStemmer and SnowballStemmer technique\n",
    "ptr_stemmer = PorterStemmer()\n",
    "ptr_stemmer.stem('fairly'), ptr_stemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac06b932-2466-471e-9a64-15e38d3d5660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_ball = SnowballStemmer('english')\n",
    "snow_ball.stem('fairly'), snow_ball.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5708ad-22a8-4eca-bb8f-1d9ed27ce0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
